{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa60458-a24f-48a7-af49-ea04121ca8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb51d70-a544-4626-84e6-ee0bfcbf4a86",
   "metadata": {},
   "source": [
    "## Create Dataset (Only run when datasets are changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc90f9e8-bc02-453a-9b00-a3db481f7ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sıkışmış hissetmek (yerine tekrar giriş yok, y...</td>\n",
       "      <td>Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yakın zamanda başka bir şehre taşındım ve nele...</td>\n",
       "      <td>Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Panik atak geçirmenin eşiğindeydim, sadece bun...</td>\n",
       "      <td>Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geçen hafta maruz kalma terapimi yaparken soka...</td>\n",
       "      <td>Disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bazen özgüven ve benlik imajıyla çok mücadele ...</td>\n",
       "      <td>Disorder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0  Sıkışmış hissetmek (yerine tekrar giriş yok, y...  Disorder\n",
       "1  Yakın zamanda başka bir şehre taşındım ve nele...  Disorder\n",
       "2  Panik atak geçirmenin eşiğindeydim, sadece bun...  Disorder\n",
       "3  Geçen hafta maruz kalma terapimi yaparken soka...  Disorder\n",
       "4  Bazen özgüven ve benlik imajıyla çok mücadele ...  Disorder"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disorder_texts = []\n",
    "for expurgated_data_path in glob.glob('../Data/Expurgated_Data/Reddit/*'):\n",
    "    #file_name = expurgated_data_path.split('/')[-1].split('.')[0]\n",
    "    disorder_df = pd.read_excel(expurgated_data_path)\n",
    "    disorder_texts.extend(disorder_df['Translated_Text'].values)\n",
    "\n",
    "disorder_df = pd.DataFrame({\n",
    "    \"Text\": disorder_texts,\n",
    "    \"Label\": \"Disorder\"\n",
    "})\n",
    "\n",
    "disorder_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dab3c27d-49c4-4e68-80ac-7f56a731f787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Translated_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So let's be clear here. I'm totally fine.\\n\\nI...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Yani burada açık olalım. Ben tamamen iyiyim. B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’m a 35 year old man, the sole income of a ho...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Ben 35 yaşında bir adamım, 3 kişilik bir evin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My life is over I’m about to be 21 and I alrea...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Hayatım bitti 21 olmak üzereyim ve zaten ölü h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just want to outlet. I’m running out of opti...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Sadece çıkış yapmak istiyorum. Seçeneklerim tü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every time I start to feel depressed (It comes...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Ne zaman depresif hissetmeye başlasam (Dalgala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text   Label  \\\n",
       "0  So let's be clear here. I'm totally fine.\\n\\nI...  Normal   \n",
       "1  I’m a 35 year old man, the sole income of a ho...  Normal   \n",
       "2  My life is over I’m about to be 21 and I alrea...  Normal   \n",
       "3  I just want to outlet. I’m running out of opti...  Normal   \n",
       "4  Every time I start to feel depressed (It comes...  Normal   \n",
       "\n",
       "                                     Translated_Text  \n",
       "0  Yani burada açık olalım. Ben tamamen iyiyim. B...  \n",
       "1  Ben 35 yaşında bir adamım, 3 kişilik bir evin ...  \n",
       "2  Hayatım bitti 21 olmak üzereyim ve zaten ölü h...  \n",
       "3  Sadece çıkış yapmak istiyorum. Seçeneklerim tü...  \n",
       "4  Ne zaman depresif hissetmeye başlasam (Dalgala...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_data = pd.read_csv('../Data/Disorder_Detection_Datasets/normal_dataset_translated_chunk_1.csv')\n",
    "normal_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c626474-bb69-441f-ae79-a9bfb6948a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame()\n",
    "\n",
    "total_df['Text'] = normal_data['Translated_Text']\n",
    "total_df['Label'] = normal_data['Label']\n",
    "\n",
    "total_df = pd.concat([total_df, disorder_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c84784cf-e8bb-429f-a10c-572228ef0da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Disorder    8850\n",
       "Normal      5000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37b80dc3-37de-4447-a173-3e25aa56e6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "total_df.to_excel('../Data/Disorder_Detection_Datasets/main_dataset.xlsx', index=False)\n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be36bc-3181-4f7c-b5e2-28865b4cfa2c",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d977bc1-ac1f-4da5-b131-873b83908ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb0b8453-8874-4799-8ce5-75e8dfed6993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yani burada açık olalım. Ben tamamen iyiyim. B...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ben 35 yaşında bir adamım, 3 kişilik bir evin ...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hayatım bitti 21 olmak üzereyim ve zaten ölü h...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sadece çıkış yapmak istiyorum. Seçeneklerim tü...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ne zaman depresif hissetmeye başlasam (Dalgala...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text   Label\n",
       "0  Yani burada açık olalım. Ben tamamen iyiyim. B...  Normal\n",
       "1  Ben 35 yaşında bir adamım, 3 kişilik bir evin ...  Normal\n",
       "2  Hayatım bitti 21 olmak üzereyim ve zaten ölü h...  Normal\n",
       "3  Sadece çıkış yapmak istiyorum. Seçeneklerim tü...  Normal\n",
       "4  Ne zaman depresif hissetmeye başlasam (Dalgala...  Normal"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../Data/Disorder_Detection_Datasets/main_dataset.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6ca6ea0-8903-4249-a60a-2a6d3687b0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12966</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Disorder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Text     Label\n",
       "12966  NaN  Disorder"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Text'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ec171e3-bf0e-49f3-934f-10903d11a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadingData():\n",
    "            \n",
    "    def __init__(self, data_path):\n",
    "        self.train = pd.read_excel(data_path)\n",
    "        self.train.dropna(inplace=True)\n",
    "        print(\"Data was read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79de0dd4-240e-4ddf-8901-042e188f12c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was read\n"
     ]
    }
   ],
   "source": [
    "ld = LoadingData(data_path=\"../Data/Disorder_Detection_Datasets/main_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e2a8a40-8b35-4b8e-8f34-884975dd3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, val_text, train_labels, val_labels = train_test_split(ld.train['Text'], ld.train['Label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify= ld.train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6697db76-557c-4eed-b51c-52912022bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")\n",
    "bert = BertModel.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1a15bd5f-5315-470a-aff9-737d2f7c5ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)\n",
    "max_seq_len = max(seq_len)\n",
    "print(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6abc550d-48b4-4d2a-b147-e2d0e47f478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "if max_seq_len>512:\n",
    "    max_seq_len = 512\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "52c79fe8-c8ef-415a-85a2-c70365a27ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11079,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_labels.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2061a51e-10f1-44a3-b8cd-6045e0270485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11421    Disorder\n",
       "11896    Disorder\n",
       "6813     Disorder\n",
       "12246    Disorder\n",
       "7993     Disorder\n",
       "           ...   \n",
       "3901       Normal\n",
       "2986       Normal\n",
       "7113     Disorder\n",
       "11865    Disorder\n",
       "13125    Disorder\n",
       "Name: Label, Length: 11079, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e84527a3-0732-4fd2-aa03-9c32e08062e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[train_labels == 'Disorder'] = 1\n",
    "train_labels[train_labels == 'Normal'] = 0\n",
    "\n",
    "val_labels[val_labels == 'Disorder'] = 1\n",
    "val_labels[val_labels == 'Normal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "adb7b1ee-d38b-4474-b09f-672fac04f5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y: tensor([1, 1, 1,  ..., 1, 1, 1])\n",
      "val_y: tensor([1, 1, 1,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.to_list())\n",
    "print(\"train_y:\",train_y)\n",
    "\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "print(\"val_y:\",val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f8f9d1b1-83dc-41b5-9537-1bd432075af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11079])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb0533c-16a4-4ba9-bf8a-dd9312de0243",
   "metadata": {},
   "source": [
    "## Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dc8d451a-8115-4870-a81a-167760a46f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "016f8187-10fa-4120-aa92-d2227c21a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "524623d3-beec-4188-ac56-02d0066c9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binary_BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(Binary_BERT_Arch, self).__init__()\n",
    "        self.bert = bert \n",
    "      \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "        \n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # apply sigmoid activation\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "08ff3d4d-5bc1-46cb-8c6e-3111518ff782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = Binary_BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a0980bc1-d9fa-4bf2-97ef-04a901af8033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "42a0dc0e-f14b-473b-b653-bee1c3c86e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.384875   0.78252578]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d2159f9a-bac1-4ab2-9a75-f8262adea2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "93f8ce51-a726-46e1-8f74-a980a7b1d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "    total_labels =[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        # append the model predictions\n",
    "        total_preds+=list(preds)\n",
    "        total_labels+=labels.tolist()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bd1c2caa-4630-43b9-8492-c69cb767a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "\n",
    "          # Calculate elapsed time in minutes.\n",
    "          #elapsed = format_time(time.time() - t0)\n",
    "\n",
    "          # Report progress.\n",
    "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "            total_preds+=list(preds)\n",
    "            total_labels+=labels.tolist()\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
    "    return avg_loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "004be738-03bc-4920-85af-0832b2a5bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(filename, epoch, model, optimizer, label_map, id2label):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'optimizer': optimizer,\n",
    "        'label_map': label_map,\n",
    "        'id_map':id2label}\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6139ed0e-1eed-4862-baba-d7cd4a81799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 100\n",
      "pooler_output\n",
      "last_hidden_state\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#train model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m train_loss, f1_train \u001b[38;5;241m=\u001b[39m train()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#evaluate model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m valid_loss, f1_valid \u001b[38;5;241m=\u001b[39m evaluate()\n",
      "Cell \u001b[1;32mIn[135], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()        \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# get model predictions for the current batch\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(sent_id, mask)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# compute the loss between actual and predicted values\u001b[39;00m\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m cross_entropy(preds, labels)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[144], line 30\u001b[0m, in \u001b[0;36mBinary_BERT_Arch.forward\u001b[1;34m(self, sent_id, mask)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(cls_hs)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(_)\n\u001b[1;32m---> 30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(cls_hs)\n\u001b[0;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, f1_train = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, f1_valid = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        file_name = 'disorder_detection_model.pt'\n",
    "        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n",
    "    print(f'\\nTraining F1: {f1_train:.3f}')\n",
    "    print(f'Validation F1: {f1_valid:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc139701-9751-4041-8ad5-71a84d6cb2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Psynexa Torch GPU (Python 3.11)",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
