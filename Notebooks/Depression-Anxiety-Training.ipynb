{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3105e248-f5cd-4322-972a-e1acd2307f2e",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b2fef6-353a-4c0c-b743-0a1b88af4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb877c55-82d3-449b-b86e-81badbc2a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "depression_data = pd.read_excel('../Data/Depression_Disorders_Data/depression_total_cleaned.xlsx')\n",
    "anxiety_data = pd.read_excel(\"../Data/Anxiety_Detection_Data/total_df_balanced.xlsx\")\n",
    "anxiety_data['labels'] = 'Anxiety'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efad8ee9-3d32-442e-a1f3-f6562b1fa485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20670</th>\n",
       "      <td>Kendimi buradan uzakta, başka bir yerde hayal ...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11883</th>\n",
       "      <td>Her gün daha da kötüleşiyorum. Bu durumdan kur...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23773</th>\n",
       "      <td>Hala kendimi 10 yaşında gibi hissediyorum ve o...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11480</th>\n",
       "      <td>Belirtilerim aniden o kadar kötü oldu ki, çalı...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>Şu anda hayatımın her yönü için endişeliyim ve...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13377</th>\n",
       "      <td>sosyal anksiyete diye bir seyi kimse isteyerek...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13378</th>\n",
       "      <td>iyileştiniz mi cok merak ediyorum ilaci tamame...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13379</th>\n",
       "      <td>arkadaşlar bende pani̇k atak anksi̇yete kaygi ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13380</th>\n",
       "      <td>Ben küçükken fazla ilgilenildim ve sevildim. H...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13381</th>\n",
       "      <td>Özgür Koca Bak herkes ayni sekilde bunu yasaya...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28382 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text      labels\n",
       "20670  Kendimi buradan uzakta, başka bir yerde hayal ...  Depression\n",
       "11883  Her gün daha da kötüleşiyorum. Bu durumdan kur...  Depression\n",
       "23773  Hala kendimi 10 yaşında gibi hissediyorum ve o...  Depression\n",
       "11480  Belirtilerim aniden o kadar kötü oldu ki, çalı...  Depression\n",
       "4135   Şu anda hayatımın her yönü için endişeliyim ve...  Depression\n",
       "...                                                  ...         ...\n",
       "13377  sosyal anksiyete diye bir seyi kimse isteyerek...     Anxiety\n",
       "13378  iyileştiniz mi cok merak ediyorum ilaci tamame...     Anxiety\n",
       "13379  arkadaşlar bende pani̇k atak anksi̇yete kaygi ...     Anxiety\n",
       "13380  Ben küçükken fazla ilgilenildim ve sevildim. H...     Anxiety\n",
       "13381  Özgür Koca Bak herkes ayni sekilde bunu yasaya...     Anxiety\n",
       "\n",
       "[28382 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = pd.DataFrame()\n",
    "\n",
    "total_df['text'] = depression_data['text'].sample(15000)\n",
    "total_df['labels'] = 'Depression'\n",
    "\n",
    "total_df = pd.concat([total_df, anxiety_data.iloc[:, :2]], axis=0)\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c898f4ac-8fb3-40db-a871-8d3e7ac463e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(total_df['labels'])\n",
    "\n",
    "concat_df = pd.concat([total_df['text'], one_hot_encoded], axis=1)\n",
    "concat_df = concat_df.dropna().reset_index(drop=True)\n",
    "\n",
    "concat_df.iloc[:, 1:] = concat_df.iloc[:, 1:].astype(int)\n",
    "\n",
    "concat_df['all_labels'] = concat_df.apply(lambda row: [label for label in one_hot_encoded.columns if row[label] == 1], axis=1)\n",
    "concat_df = concat_df.loc[:, ['text', 'Depression', 'Anxiety', 'all_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d389418-72b9-4b97-9dd7-47eb9ccd608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "Dataset.cleanup_cache_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(concat_df, test_size = 0.25, random_state=42)\n",
    "\n",
    "train_data = Dataset.from_pandas(train, preserve_index=False)\n",
    "test_data = Dataset.from_pandas(test, preserve_index=False)\n",
    "\n",
    "hg_data = DatasetDict({\n",
    "    \"train\": train_data,\n",
    "    \"test\": test_data\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6778d2b6-254d-4ac6-a6a7-23c825ed0f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'Depression', 'Anxiety', 'all_labels'],\n",
       "        num_rows: 21285\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Depression', 'Anxiety', 'all_labels'],\n",
       "        num_rows: 7096\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65dc3b9f-e998-4d19-bba3-56121eec240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\halilibrahim.hatun\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524dd9473c7c4e359ad0849765f9d590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5148287995744c8b84e91b0747bcd409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14f6ff8eeb949bf803f0a7f282afe39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c172ff00ef524ebfa3cc20af6130d086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was pushed :)\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token=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\n",
    "\n",
    "hg_data.push_to_hub(\"halilibr/dilbazlar-anxiety-depression-recognition-multilabel-tr-dataset\")\n",
    "print(\"Data was pushed :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73421ffc-0064-4665-a892-a47333a0d16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee2b175e6944295baf92488db148c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/21285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6e4040400b430897ef34a159b4f2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/7096 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hg_data.save_to_disk('../Data/Depression_Disorders_Data/depression_anxiety_multilabel_hg_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ceb41-586a-42a2-b7c3-b32b79f7fa4b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fbe4ea7-5434-4ebc-a6f1-fc4f020fa35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55c20532-37b3-41d0-8b8e-30223032938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from disk\n",
    "dataset = load_from_disk('../Data/Depression_Disorders_Data/depression_anxiety_multilabel_hg_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "758a63a4-e408-4daf-b28f-d81dbc2152fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'Depression', 'Anxiety', 'all_labels'],\n",
       "        num_rows: 21285\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'Depression', 'Anxiety', 'all_labels'],\n",
       "        num_rows: 7096\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c59e598-42b0-415e-85c2-ef25c6413d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Depression', 'Anxiety']\n",
    "class2id = {class_:id for id, class_ in enumerate(classes)}\n",
    "id2class = {id:class_ for class_, id in class2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ae4be9c-d286-4f2b-a830-01882aee02e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Depression': 0, 'Anxiety': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24a2551c-277d-4be2-a35d-938518963c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = 'dbmdz/bert-base-turkish-128k-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36a0eaa7-15ff-4d0b-86d3-87d29a867d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131560997a704b0aa8f401517c5b3ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df60b5f6ab74818878ee3ba82fafe06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7096 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(example):\n",
    "    \n",
    "    text = f\"{example['text']}\"\n",
    "\n",
    "    \n",
    "    all_labels = example['all_labels']\n",
    "    labels = [0. for i in range(len(classes))]\n",
    "\n",
    "    for label in all_labels:\n",
    "        label_id = class2id[label]\n",
    "        labels[label_id] = 1.\n",
    "\n",
    "    example = tokenizer(text, truncation=True)\n",
    "    example['labels'] = labels\n",
    "    return example\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4e83cc3-a697-4b5e-86d9-d3ac1a513938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Sadece her zaman dile ilgim olduğu için öğrenmeyi denedim..ama hiçbir zaman gerçek yaşam durumlarında pratik yapma veya kullanma fırsatım olmadı, çünkü çoğu insanla etkileşime girmem gerekiyor.',\n",
       " 'Depression': 0,\n",
       " 'Anxiety': 1,\n",
       " 'all_labels': ['Anxiety'],\n",
       " 'input_ids': [2,\n",
       "  2577,\n",
       "  2110,\n",
       "  2211,\n",
       "  4095,\n",
       "  41574,\n",
       "  15500,\n",
       "  8059,\n",
       "  28519,\n",
       "  3338,\n",
       "  19312,\n",
       "  18,\n",
       "  18,\n",
       "  2156,\n",
       "  42283,\n",
       "  2211,\n",
       "  16599,\n",
       "  28932,\n",
       "  27691,\n",
       "  7089,\n",
       "  4386,\n",
       "  2358,\n",
       "  6657,\n",
       "  38174,\n",
       "  6853,\n",
       "  16,\n",
       "  29146,\n",
       "  63566,\n",
       "  24178,\n",
       "  16061,\n",
       "  5055,\n",
       "  1011,\n",
       "  33351,\n",
       "  3814,\n",
       "  18,\n",
       "  3],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [0.0, 1.0]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b876a875-1696-42fb-be18-80c49407c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a49d1b72-368f-4a6e-9d87-03f0ec465e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "   predictions, labels = eval_pred\n",
    "   predictions = sigmoid(predictions)\n",
    "   predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "   return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bd45df7-ed22-4aa9-858a-010a87ea1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "   model_path, num_labels=len(classes),\n",
    "           id2label=id2class, label2id=class2id,\n",
    "                       problem_type = \"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbc8141c-1386-453a-8f1d-cb4f0984c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"]=\"Dilbazlar\"\n",
    "wandb_api_key = \"04a083b14d60688b24482e00727ebcc57448ef88\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dc27525-580c-41a8-ac70-042af85cac7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhalil7hatun\u001b[0m (\u001b[33muniteks\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\halilibrahim.hatun\\Documents\\TEKNOFEST-Dilbazlar\\Notebooks\\wandb\\run-20240803_173910-xkfqxgkm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uniteks/Dilbazlar/runs/xkfqxgkm' target=\"_blank\">depression-specific-augmented-model</a></strong> to <a href='https://wandb.ai/uniteks/Dilbazlar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uniteks/Dilbazlar' target=\"_blank\">https://wandb.ai/uniteks/Dilbazlar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uniteks/Dilbazlar/runs/xkfqxgkm' target=\"_blank\">https://wandb.ai/uniteks/Dilbazlar/runs/xkfqxgkm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14190' max='14190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14190/14190 29:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.266273</td>\n",
       "      <td>0.950395</td>\n",
       "      <td>0.950395</td>\n",
       "      <td>0.950395</td>\n",
       "      <td>0.950395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.270781</td>\n",
       "      <td>0.953918</td>\n",
       "      <td>0.953911</td>\n",
       "      <td>0.954046</td>\n",
       "      <td>0.953777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14190, training_loss=0.20305133319556334, metrics={'train_runtime': 1808.9339, 'train_samples_per_second': 23.533, 'train_steps_per_second': 7.844, 'total_flos': 1384265290018680.0, 'train_loss': 0.20305133319556334, 'epoch': 2.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "   output_dir=\"depression_disorders_model\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=3,\n",
    "   per_device_eval_batch_size=3,\n",
    "   num_train_epochs=3,\n",
    "   weight_decay=0.01,\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "   load_best_model_at_end=True,\n",
    "   report_to=[\"wandb\"],# Wandb = https://docs.wandb.ai/guides/integrations/huggingface\n",
    "   run_name=\"depression-specific-augmented-model\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_dataset[\"train\"],\n",
    "   eval_dataset=tokenized_dataset[\"test\"],\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05869718-583b-489a-9830-82b4cd43988f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "407dacfa-ee5e-49d5-b18f-f556f52631c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28fa4c2e-2d9f-4833-958a-70d0ee6bff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anxiety_labels = ['Depression', 'Anxiety']\n",
    "\n",
    "\n",
    "def predict(model, tokenizer, labels, input_text):\n",
    "    # Tokenize the input (ensure the tokenizer is appropriate for your model)\n",
    "    inputs = tokenizer(input_text, max_length=150, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # Move the inputs to the appropriate device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        # Forward pass to get outputs\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        # Get the prediction\n",
    "        # Note: `AutoModel` might not include logits. Ensure you use the appropriate model class for your task.\n",
    "        if hasattr(outputs, 'logits'):\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "        else:\n",
    "            # Handle the case where the model does not have logits (e.g., outputs are raw hidden states)\n",
    "            preds = torch.argmax(outputs[0], dim=-1)\n",
    "    \n",
    "    # Convert prediction to numpy array and print (if needed)\n",
    "    prediction = preds.cpu().numpy()[0]\n",
    "    print(outputs)\n",
    "    return labels[prediction] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7e6ad4f-3888-46bf-8450-40eb1ee98d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[ 5.1898, -5.2543]], device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Depression'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Uykusuzum\"\n",
    "\n",
    "predict(trainer.model, trainer.tokenizer, anxiety_labels, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c3131-5b4b-4d8b-ad3f-798fce234187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Psynexa Torch GPU (Python 3.11)",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
