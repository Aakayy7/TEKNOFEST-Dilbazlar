{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae60561d-ca57-48e7-9a53-531cdbcfdb89",
   "metadata": {},
   "source": [
    "## Kütüphaneleri Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be87c1f3-27f8-40a9-b8c3-6eb08c4624d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66defd6-9767-4276-b29b-d317419d35f9",
   "metadata": {},
   "source": [
    "## Veriyi Okuma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc0a12e-d883-4ea9-b153-8954e907b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../Data/Anxiety_Detection_Data/total_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c9ef8b-fbeb-4f75-8b8c-0f122be83bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c974a4c3-5809-45a8-a392-fa4f364883ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19144 entries, 0 to 19143\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    19143 non-null  object\n",
      " 1   labels  19144 non-null  object\n",
      " 2   source  19144 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 448.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244eb4f0-905e-49c9-be19-b5530c74a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19144 entries, 0 to 19143\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    19143 non-null  object\n",
      " 1   labels  19144 non-null  object\n",
      " 2   source  19144 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 448.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed39881-d739-425a-a599-361574bcc309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sıkışmış hissetmek (yerine tekrar giriş yok, yiyecek ve içecek yok)</td>\n",
       "      <td>agoraphobia</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yakın zamanda başka bir şehre taşındım ve neler olduğunu bilmiyorum, ama etrafımdaki herkes hakkımda bok konuşuyor, komşularım benden nefret ediyor ve beni rahatsız etmek için beni aşağılamaya veya yere vurmaya devam ediyor, kasabamdaki insanlar benimle ilgili dedikodu yapıyor, artık arkadaşlarımla dışarı çıkamıyorum çünkü herkes benden nefret ediyor, ne yapacağımı bilmiyorum ve bunun neden olduğunu anlamıyorum, her gün panik atak geçiriyorum</td>\n",
       "      <td>agoraphobia</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Panik atak geçirmenin eşiğindeydim, sadece bunu düşünüyordum.</td>\n",
       "      <td>agoraphobia</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geçen hafta maruz kalma terapimi yaparken sokakta panik atak geçirdim. İyileşmek için merdivende birkaç basamak düşürülmüş gibi hissediyorum. Bir zamanlar önemsiz görevlerin tekrar panik tepkisine neden olduğu bu tür aksilikler yaşayan başka biri var mı?</td>\n",
       "      <td>agoraphobia</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bazen özgüven ve benlik imajıyla çok mücadele ediyorum.</td>\n",
       "      <td>agoraphobia</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                             text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                             Sıkışmış hissetmek (yerine tekrar giriş yok, yiyecek ve içecek yok)   \n",
       "1  Yakın zamanda başka bir şehre taşındım ve neler olduğunu bilmiyorum, ama etrafımdaki herkes hakkımda bok konuşuyor, komşularım benden nefret ediyor ve beni rahatsız etmek için beni aşağılamaya veya yere vurmaya devam ediyor, kasabamdaki insanlar benimle ilgili dedikodu yapıyor, artık arkadaşlarımla dışarı çıkamıyorum çünkü herkes benden nefret ediyor, ne yapacağımı bilmiyorum ve bunun neden olduğunu anlamıyorum, her gün panik atak geçiriyorum   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                   Panik atak geçirmenin eşiğindeydim, sadece bunu düşünüyordum.   \n",
       "3                                                                                                                                                                                                  Geçen hafta maruz kalma terapimi yaparken sokakta panik atak geçirdim. İyileşmek için merdivende birkaç basamak düşürülmüş gibi hissediyorum. Bir zamanlar önemsiz görevlerin tekrar panik tepkisine neden olduğu bu tür aksilikler yaşayan başka biri var mı?   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                         Bazen özgüven ve benlik imajıyla çok mücadele ediyorum.   \n",
       "\n",
       "        labels  source  \n",
       "0  agoraphobia  Reddit  \n",
       "1  agoraphobia  Reddit  \n",
       "2  agoraphobia  Reddit  \n",
       "3  agoraphobia  Reddit  \n",
       "4  agoraphobia  Reddit  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f494ec9-1410-4bc6-92fb-39f05b320e3c",
   "metadata": {},
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-tc-big-en-tr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Çeviri fonksiyonunu tanımla\n",
    "def translate_text(text):\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\", padding=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "# DataFrame'deki her satır için çeviri işlemi uygula ve yeni bir kolona ekle\n",
    "data['Translated_Text'] = data['Text'].apply(translate_text)\n",
    "\n",
    "# Sonuçları göster\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81098c73-25c1-49e9-9a55-69ab399cc141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halilibrahim.hatun\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(57060, 1024, padding_idx=57059)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(57060, 1024, padding_idx=57059)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(1024, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(57060, 1024, padding_idx=57059)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(1024, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=57060, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-tc-big-en-tr\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c229d8c-23d3-432e-847c-ae051c2e1ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Process:   1%|▍                                                               | 33/4786 [01:57<4:41:54,  3.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39656\\1059967444.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtranslated_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_translate_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Translated_Text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslated_texts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39656\\1059967444.py\u001b[0m in \u001b[0;36mbatch_translate_text\u001b[1;34m(texts, batch_size)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mbatch_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtranslated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mtranslated_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtranslated_texts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslated_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\torch\\utils\\_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             )\n\u001b[0;32m   1796\u001b[0m             \u001b[1;31m# 13. run beam search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1798\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3233\u001b[0m             \u001b[1;31m# stateless\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3234\u001b[1;33m             beam_outputs = beam_scorer.process(\n\u001b[0m\u001b[0;32m   3235\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3236\u001b[0m                 \u001b[0mnext_token_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\transformers\\generation\\beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[0mbeam_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             for beam_token_rank, (next_token, next_score, next_index) in enumerate(\n\u001b[1;32m--> 267\u001b[1;33m                 \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m             ):\n\u001b[0;32m    269\u001b[0m                 \u001b[0mbatch_beam_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnext_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\psynexa_torch_cpu\\Lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 980\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    981\u001b[0m         \u001b[1;31m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[1;31m# generator and don't eagerly perform all the indexes.  This could\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def batch_translate_text(texts, batch_size=4):\n",
    "    translated_texts = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Translating Process\"):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        translated = model.generate(**inputs)\n",
    "        translated_batch = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "        translated_texts.extend(translated_batch)\n",
    "        del inputs, translated  # Free up memory\n",
    "        torch.cuda.empty_cache()\n",
    "    return translated_texts\n",
    "\n",
    "texts = data['text'].tolist()\n",
    "translated_texts = batch_translate_text(texts)\n",
    "\n",
    "data['Translated_Text'] = translated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05dc134e-df43-46ff-8dfd-2315d8a54b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"../Data/dysthymia_to_tr.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f3815-5a4e-42e0-959f-a318e13f1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b1b2f-94dc-4077-9211-0d6ef29f1277",
   "metadata": {},
   "source": [
    "data.to_csv(\"agoraphobia_translated_to_tr\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1197b1-898c-4626-beda-e326e15aa4db",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"agoraphobia_translated_to_tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60491970-4954-4666-8775-3a3a3063a598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
