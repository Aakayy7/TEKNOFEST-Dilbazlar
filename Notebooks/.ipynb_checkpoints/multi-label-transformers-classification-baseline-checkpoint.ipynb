{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('knowledgator/events_classification_biotech') \n",
    "    \n",
    "classes = [class_ for class_ in dataset['train'].features['label 1'].names if class_]\n",
    "class2id = {class_:id for id, class_ in enumerate(classes)}\n",
    "id2class = {id:class_ for class_, id in class2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': \"Sarah Polley's Book Recommendations\",\n",
       " 'content': 'Drive Your Plow Over the Bones of The Dead\\nby Olga Tokarczuk. I am an incredibly slow reader, but the tone and specificity of the world she creates in this book was something I couldnt leave behind until it was done. Also: All We Sawby Anne Michaels, Fight Nightby Miriam Toews, and The Summer Before the Darkby Doris Lessing.\\nId like turned into a Netflix show:\\nby Amia Srinivasan. One of the most brain-shattering books Ive ever read. Her thinking is so electrically rigorous and fearless. (I double DARE them to make this into a Netflix show!)\\n...I last bought:\\n. I rediscovered her poetry lately, and I feel like I dont want to read anything else for a while. She owns desire and submerged things.\\n...has the greatest ending:\\nby J.D. Salinger. The last page always leaves me breathless. The intimacy and truth of that final page is so arresting and almost painful to read.\\nshould be on every college syllabus:\\nby Anton Piatigorsky. A fascinating fictional account of the adolescence of dictators. It is painstakingly researched and so imaginative. He takes on whole histories through a small, specific, human lens.\\n...Ive re-read the most:\\nGilead\\nby Marilynne Robinson. It reminds me of the wild depths of kindness humans are capable of. It helps me get to sleep when Im agitated. It is so incredibly gentle, complex, wise and hopeful. It gives me a glimpse into what faith can feel like.\\n...that holds the recipe to a favorite dish:\\nMarcella Hazans tomato butter onion sauce from Essentials of Classic Italian Cooking I discovered it when I was 17. No matter how much I cook, Ive never found anything that matches the pure magic of what these three simple ingredients do together.\\nBonus question: If I could live in any library or bookstore in the world, it would be:',\n",
       " 'target organization': \"Franny's Farmacy\",\n",
       " 'all_labels': ['other'],\n",
       " 'all_labels_concat': 'other',\n",
       " 'label 1': 23,\n",
       " 'label 2': None,\n",
       " 'label 3': None,\n",
       " 'label 4': None,\n",
       " 'label 5': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = 'microsoft/deberta-v3-small'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ff07e92fb54e968385a74baeed78f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/381 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(example):\n",
    "    \n",
    "    text = f\"{example['title']}.\\n{example['content']}\"\n",
    "\n",
    "    \n",
    "    all_labels = example['all_labels']\n",
    "    labels = [0. for i in range(len(classes))]\n",
    "\n",
    "    for label in all_labels:\n",
    "        label_id = class2id[label]\n",
    "        labels[label_id] = 1.\n",
    "\n",
    "    example = tokenizer(text, truncation=True)\n",
    "    example['labels'] = labels\n",
    "    return example\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': \"Sarah Polley's Book Recommendations\",\n",
       " 'content': 'Drive Your Plow Over the Bones of The Dead\\nby Olga Tokarczuk. I am an incredibly slow reader, but the tone and specificity of the world she creates in this book was something I couldnt leave behind until it was done. Also: All We Sawby Anne Michaels, Fight Nightby Miriam Toews, and The Summer Before the Darkby Doris Lessing.\\nId like turned into a Netflix show:\\nby Amia Srinivasan. One of the most brain-shattering books Ive ever read. Her thinking is so electrically rigorous and fearless. (I double DARE them to make this into a Netflix show!)\\n...I last bought:\\n. I rediscovered her poetry lately, and I feel like I dont want to read anything else for a while. She owns desire and submerged things.\\n...has the greatest ending:\\nby J.D. Salinger. The last page always leaves me breathless. The intimacy and truth of that final page is so arresting and almost painful to read.\\nshould be on every college syllabus:\\nby Anton Piatigorsky. A fascinating fictional account of the adolescence of dictators. It is painstakingly researched and so imaginative. He takes on whole histories through a small, specific, human lens.\\n...Ive re-read the most:\\nGilead\\nby Marilynne Robinson. It reminds me of the wild depths of kindness humans are capable of. It helps me get to sleep when Im agitated. It is so incredibly gentle, complex, wise and hopeful. It gives me a glimpse into what faith can feel like.\\n...that holds the recipe to a favorite dish:\\nMarcella Hazans tomato butter onion sauce from Essentials of Classic Italian Cooking I discovered it when I was 17. No matter how much I cook, Ive never found anything that matches the pure magic of what these three simple ingredients do together.\\nBonus question: If I could live in any library or bookstore in the world, it would be:',\n",
       " 'target organization': \"Franny's Farmacy\",\n",
       " 'all_labels': ['other'],\n",
       " 'all_labels_concat': 'other',\n",
       " 'label 1': 23,\n",
       " 'label 2': None,\n",
       " 'label 3': None,\n",
       " 'label 4': None,\n",
       " 'label 5': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ShiraTronics, Inc. Completes $33M Million Series A Financing',\n",
       " 'content': 'ShiraTronics, Inc. Completes $33M Million Series A Financing\\nSearch jobs\\n24-Oct-2019\\nShiraTronics, Inc. Completes $33M Million Series A Financing\\nMINNEAPOLIS, Oct. 24, 2019 /PRNewswire/ --ShiraTronics, Inc., a private medical device company, today announced it has completed a Series A financing of $33 million.The financing was co-led by USVP, Amzak Health, and Strategic HealthCare Investment Partners (S.H.I.P.), with participation from Aperture Ventures, LivaNova PLC, and a leading Academic Institution. Concurrent with the financing, the company also announced the hiring of Lynn Elliott as the President and CEO of the Company. Lynn brings three decades of active implantable device experience in medical device innovation, R&D, manufacturing, clinical trials, and regulatory approvals to healthcare challenges. Lynn has a unique blend of experience in large medical device companies such as Guidant and Boston Scientific and small venture capital funded startups like Spinal Modulation and ShiraTronics.\\nAs part of this financing Casey Tansey (USVP), Joyce Erony (Amzak Health), and Brad H.Vale, PhD, DVM (S.H.I.P.) will join the ShiraTronics Board.\\nShiraTronics was seeded in 2019 and is the first spin off from NuXcel, a medical device accelerator managed by Mudit K. Jain, PhD, and Lynn Elliott, and backed by S.H.I.P. Supported by meaningful body of clinical evidence, ShiraTronics is developing an innovative approach to treat migraine headaches which are a disabling disorder affecting millions of patients globally.\\n\"ShiraTronics is leveraging significant clinical experience to accelerate the development of a novel therapy that may significantly impact the lives of millions of patients who suffer from migraine headaches. We are very excited to be part of the company\\'s evolution and future growth,\" said Casey Tansey, General Partner, USVP, and a newly appointed board member of ShiraTronics.\\n\"We look forward to partnering with such an experienced investor group led by USVP, Amzak, and S.H.I.P. This financing provides us the necessary resources needed to develop and advance a novel therapy in the clinics,\" said Lynn Elliott the President and Chief Executive Officer of ShiraTronics. \"We are absolutely thrilled to have the first spin-off from NuXcel off to a great start with a world-class syndicate of very seasoned medical device investors and are looking forward to working with them, the product development team, and the clinical community in further developing this impactful technology,\" said Mudit K. Jain, PhD, a co-founder and Chairman of the Board of ShiraTronics.\\nAbout ShiraTronics:\\nwww.shiratronics.com\\nShiraTronics, Inc., Brooklyn Park, Minnesota, was created to be the world\\'s leading provider of innovative therapy for migraine headaches. The company is focused on developing and clinically testing its neuromodulation technology. The company was spun off from NuXcel, an electrical medical device focused accelerator. The leadership team of ShiraTronics has overseen the development of several active implantable devices and brought them to the market over last 30 years.\\nAbout NuXcel:\\nwww.nuxcel.com\\n\\nNuXcel was established in late 2018 and is a global medical device accelerator focused on developing innovative solutions to serve large unmet clinical needs with presence in Ireland and USA and backed by S.H.I.P.\\nView original content:',\n",
       " 'target organization': 'ShiraTronics',\n",
       " 'all_labels': ['funding round', 'executive statement'],\n",
       " 'all_labels_concat': 'funding round, executive statement',\n",
       " 'label 1': 28,\n",
       " 'label 2': 1,\n",
       " 'label 3': None,\n",
       " 'label 4': None,\n",
       " 'label 5': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>target organization</th>\n",
       "      <th>all_labels</th>\n",
       "      <th>all_labels_concat</th>\n",
       "      <th>label 1</th>\n",
       "      <th>label 2</th>\n",
       "      <th>label 3</th>\n",
       "      <th>label 4</th>\n",
       "      <th>label 5</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sarah Polley's Book Recommendations</td>\n",
       "      <td>Drive Your Plow Over the Bones of The Dead\\nby...</td>\n",
       "      <td>Franny's Farmacy</td>\n",
       "      <td>[other]</td>\n",
       "      <td>other</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 4537, 16649, 3342, 280, 268, 2538, 34800, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denel staff get millions from attached bank ac...</td>\n",
       "      <td>In the recently tabled National Budget, Denel ...</td>\n",
       "      <td>Heat Relief</td>\n",
       "      <td>[other]</td>\n",
       "      <td>other</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 11289, 3212, 979, 350, 3543, 292, 3448, 18...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to master productive pausing and get more ...</td>\n",
       "      <td>Shares\\nTake a break its good for you (Picture...</td>\n",
       "      <td>Reframe</td>\n",
       "      <td>[other]</td>\n",
       "      <td>other</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 577, 264, 2549, 5769, 45482, 263, 350, 310...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Early Bird &amp; Eight Certifications! RESO Weekly...</td>\n",
       "      <td>RESO is currently hiring for two positions:\\nP...</td>\n",
       "      <td>CARE SOUTH</td>\n",
       "      <td>[other]</td>\n",
       "      <td>other</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 5268, 8687, 429, 12913, 69051, 300, 40337,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Lifetime Discount Club</td>\n",
       "      <td>Charter Buyer Club\\nWhat is the Charter Buyer ...</td>\n",
       "      <td>Big Sky Botanicals</td>\n",
       "      <td>[other]</td>\n",
       "      <td>other</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 279, 19178, 12236, 2057, 260, 12689, 14861...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>Birmingham Mail backs 2025 Invictus Games bid</td>\n",
       "      <td>0\\nA regional daily wants to bring an internat...</td>\n",
       "      <td>Invictus Games</td>\n",
       "      <td>[support &amp; philanthropy, company description]</td>\n",
       "      <td>support &amp; philanthropy, company description</td>\n",
       "      <td>26</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 8668, 7624, 396, 268, 19291, 85515, 3819, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>R1 RCM Inc. (RCM) Reveals an Earnings Mystery</td>\n",
       "      <td>Share on whatsapp\\nR1 RCM Inc. (NASDAQ:RCM)\\nw...</td>\n",
       "      <td>ABCS RCM</td>\n",
       "      <td>[investment in public company, company descrip...</td>\n",
       "      <td>investment in public company, company description</td>\n",
       "      <td>22</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 909, 435, 90421, 1326, 260, 287, 17944, 11...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>Verboso Launches Full-Stack Online Speech Ther...</td>\n",
       "      <td>Verboso Launches Full-Stack Online Speech Ther...</td>\n",
       "      <td>Verboso</td>\n",
       "      <td>[product launching &amp; presentation]</td>\n",
       "      <td>product launching &amp; presentation</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 36024, 27357, 67980, 3306, 271, 56865, 230...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>Barnet, Enfield and Haringey Mental Health Tru...</td>\n",
       "      <td>Barnet, Enfield and Haringey Mental Health Tru...</td>\n",
       "      <td>Barnet Enfield and Haringey Mental Health Trust</td>\n",
       "      <td>[executive statement]</td>\n",
       "      <td>executive statement</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 56259, 261, 42149, 263, 110553, 11099, 151...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>Genprex Announces First Patient Dosed in Phase...</td>\n",
       "      <td>Genprex, Inc.\\n(Genprex or the Company) (NASDA...</td>\n",
       "      <td>Lung Biotechnology</td>\n",
       "      <td>[company description]</td>\n",
       "      <td>company description</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1, 6481, 9894, 982, 52797, 1244, 14064, 44651...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2759 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                   Sarah Polley's Book Recommendations   \n",
       "1     Denel staff get millions from attached bank ac...   \n",
       "2     How to master productive pausing and get more ...   \n",
       "3     Early Bird & Eight Certifications! RESO Weekly...   \n",
       "4                            The Lifetime Discount Club   \n",
       "...                                                 ...   \n",
       "2754      Birmingham Mail backs 2025 Invictus Games bid   \n",
       "2755      R1 RCM Inc. (RCM) Reveals an Earnings Mystery   \n",
       "2756  Verboso Launches Full-Stack Online Speech Ther...   \n",
       "2757  Barnet, Enfield and Haringey Mental Health Tru...   \n",
       "2758  Genprex Announces First Patient Dosed in Phase...   \n",
       "\n",
       "                                                content  \\\n",
       "0     Drive Your Plow Over the Bones of The Dead\\nby...   \n",
       "1     In the recently tabled National Budget, Denel ...   \n",
       "2     Shares\\nTake a break its good for you (Picture...   \n",
       "3     RESO is currently hiring for two positions:\\nP...   \n",
       "4     Charter Buyer Club\\nWhat is the Charter Buyer ...   \n",
       "...                                                 ...   \n",
       "2754  0\\nA regional daily wants to bring an internat...   \n",
       "2755  Share on whatsapp\\nR1 RCM Inc. (NASDAQ:RCM)\\nw...   \n",
       "2756  Verboso Launches Full-Stack Online Speech Ther...   \n",
       "2757  Barnet, Enfield and Haringey Mental Health Tru...   \n",
       "2758  Genprex, Inc.\\n(Genprex or the Company) (NASDA...   \n",
       "\n",
       "                                  target organization  \\\n",
       "0                                    Franny's Farmacy   \n",
       "1                                         Heat Relief   \n",
       "2                                             Reframe   \n",
       "3                                          CARE SOUTH   \n",
       "4                                  Big Sky Botanicals   \n",
       "...                                               ...   \n",
       "2754                                   Invictus Games   \n",
       "2755                                         ABCS RCM   \n",
       "2756                                          Verboso   \n",
       "2757  Barnet Enfield and Haringey Mental Health Trust   \n",
       "2758                               Lung Biotechnology   \n",
       "\n",
       "                                             all_labels  \\\n",
       "0                                               [other]   \n",
       "1                                               [other]   \n",
       "2                                               [other]   \n",
       "3                                               [other]   \n",
       "4                                               [other]   \n",
       "...                                                 ...   \n",
       "2754      [support & philanthropy, company description]   \n",
       "2755  [investment in public company, company descrip...   \n",
       "2756                 [product launching & presentation]   \n",
       "2757                              [executive statement]   \n",
       "2758                              [company description]   \n",
       "\n",
       "                                      all_labels_concat  label 1  label 2  \\\n",
       "0                                                 other       23      NaN   \n",
       "1                                                 other       23      NaN   \n",
       "2                                                 other       23      NaN   \n",
       "3                                                 other       23      NaN   \n",
       "4                                                 other       23      NaN   \n",
       "...                                                 ...      ...      ...   \n",
       "2754        support & philanthropy, company description       26     21.0   \n",
       "2755  investment in public company, company description       22     21.0   \n",
       "2756                   product launching & presentation       14      NaN   \n",
       "2757                                executive statement        1      NaN   \n",
       "2758                                company description       21      NaN   \n",
       "\n",
       "      label 3  label 4  label 5  \\\n",
       "0         NaN      NaN      NaN   \n",
       "1         NaN      NaN      NaN   \n",
       "2         NaN      NaN      NaN   \n",
       "3         NaN      NaN      NaN   \n",
       "4         NaN      NaN      NaN   \n",
       "...       ...      ...      ...   \n",
       "2754      NaN      NaN      NaN   \n",
       "2755      NaN      NaN      NaN   \n",
       "2756      NaN      NaN      NaN   \n",
       "2757      NaN      NaN      NaN   \n",
       "2758      NaN      NaN      NaN   \n",
       "\n",
       "                                              input_ids  \\\n",
       "0     [1, 4537, 16649, 3342, 280, 268, 2538, 34800, ...   \n",
       "1     [1, 11289, 3212, 979, 350, 3543, 292, 3448, 18...   \n",
       "2     [1, 577, 264, 2549, 5769, 45482, 263, 350, 310...   \n",
       "3     [1, 5268, 8687, 429, 12913, 69051, 300, 40337,...   \n",
       "4     [1, 279, 19178, 12236, 2057, 260, 12689, 14861...   \n",
       "...                                                 ...   \n",
       "2754  [1, 8668, 7624, 396, 268, 19291, 85515, 3819, ...   \n",
       "2755  [1, 909, 435, 90421, 1326, 260, 287, 17944, 11...   \n",
       "2756  [1, 36024, 27357, 67980, 3306, 271, 56865, 230...   \n",
       "2757  [1, 56259, 261, 42149, 263, 110553, 11099, 151...   \n",
       "2758  [1, 6481, 9894, 982, 52797, 1244, 14064, 44651...   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "2754  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2755  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2756  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2757  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2758  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         attention_mask  \\\n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "2754  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2755  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2756  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2757  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2758  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "2754  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2755  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2756  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2757  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2758  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[2759 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08e9d49b8a04bf2b9460db25fc63506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f51e9ccb0447c0821efd092faf5150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab8e6686f74467dbebc74608ba3fff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27848c6b1a148beafedaa51792f458f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = sigmoid(predictions)\n",
    "    predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "    return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))\n",
    "    references=labels.astype(int).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "\n",
    "   model_path, num_labels=len(classes),\n",
    "           id2label=id2class, label2id=class2id,\n",
    "                       problem_type = \"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"]=\"Dilbazlar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = \"04a083b14d60688b24482e00727ebcc57448ef88\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\halilibrahim.hatun\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\halilibrahim.hatun\\Documents\\TEKNOFEST-Dilbazlar\\Notebooks\\wandb\\run-20240722_155003-c79ao9l9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uniteks/Dilbazlar/runs/c79ao9l9' target=\"_blank\">Multi-label-model-baseline</a></strong> to <a href='https://wandb.ai/uniteks/Dilbazlar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uniteks/Dilbazlar' target=\"_blank\">https://wandb.ai/uniteks/Dilbazlar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uniteks/Dilbazlar/runs/c79ao9l9' target=\"_blank\">https://wandb.ai/uniteks/Dilbazlar/runs/c79ao9l9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1840' max='1840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1840/1840 5:30:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.146006</td>\n",
       "      <td>0.949588</td>\n",
       "      <td>0.367764</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.246951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.134350</td>\n",
       "      <td>0.955833</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.390244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 29\u001b[0m\n\u001b[0;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m    model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m    compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 29\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "   output_dir=\"my_awesome_model\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=3,\n",
    "   per_device_eval_batch_size=3,\n",
    "   num_train_epochs=2,\n",
    "   weight_decay=0.01,\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "   load_best_model_at_end=True,\n",
    "   report_to=\"wandb\", # Wandb = https://docs.wandb.ai/guides/integrations/huggingface\n",
    "   run_name=\"Multi-label-model-baseline\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_dataset[\"train\"],\n",
    "   eval_dataset=tokenized_dataset[\"test\"],\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Psynexa Torch GPU (Python 3.11)",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
